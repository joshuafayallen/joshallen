---
title: "Translating What I know in the tidyverse to polars:"
subtitle: "wrangling data with polars "
date: last-modified
date-format: "MMM D, YYYY"
description: "This is me learning the snake language"
categories:
  - r
  - tidyverse
  - python
  - polars
---


I suppose at some point it is good to become more well versed in lots of tools. I have been python curious for about a year or so and I think it is important to use the tool best suited for the task. Also sometimes it is important to get out of your comfort zone. I am definitely somebody who is very comfortable in R and the `tidyverse` and use it for a lot of stuff. I have heard lots of ravings about polars specifically about its speed and similarities in intuition with the tidyverse. So I thought I would have a collection of code for myself and the people of the internet to reference. 


Just a disclaimer. This is really just me working through the similarities and is going to be based on the [tidyintelligence's blog post](https://blog.tidy-intelligence.com/posts/dplyr-vs-polars/), [Robert Mitchell's blog post](https://robertmitchellv.com/blog/2022-07-r-python-side-by-side/r-python-side-by-side.html), and [Emily Rieder's blog post](https://www.emilyriederer.com/post/py-rgo-polars/). In all honesty, this is just for me to smash them together to have a one-stop shop for myself. If you found this post over these resources I highly recommend you check out these resources. 



# The Basics 

As always we should load in the respective packages we are going to use. 

```{r}
#| include: false
#| echo: false 
pacman::p_load(reticulate)



py_install(c("polars", "pandas", "pyjanitor", "palmerpenguins", "numpy", "pyarrow",
             "palmerpenguins", "setuptools"))




```



:::{.panel-tabset}
## R 

```{r}
suppressPackageStartupMessages(library(tidyverse))
library(palmerpenguins)

```


## Python 


```{python}
import polars as pl
import polars.selectors as cs
from palmerpenguins import load_penguins


penguins = load_penguins().pipe(pl.from_pandas)

pl.Config(tbl_rows = 10)



```



:::


Okay so far nothing too crazy! The main difference in loading in the packages and the data we are using is really just that to get with our familiar `starts_with` friends from the tidyverse we have to add `polars.selectors` and change some defaults. Lots of the time we would like to see the top and bottom portion and the column types. In `R` this is just our `head`, `tail`, `glimpse/str` in python it should be broadly similar. 


:::{.panel-tabset}

## R 

```{r}
head(penguins) |>
knitr::kable(booktabs = TRUE)


```


## Python

```{python}

penguins.head()


```

:::

So one big difference for me is that when you are doing things with objects instead of feeding them directly to head you are doing `object_name.head()` which I suppose will take some time to get used to. I suppose for completeness we should look at the glimpse equivalent since I use that function all the time 


:::{.panel-tabset}

## R

```{r}

glimpse(penguins)

```

## Python


```{python}

penguins.glimpse()

```

:::


Okay! What is cool for me so far about polars is that it is more getting used to the whole `.` thing. 


# Filter

One of the key things in data cleaning or working with data is working with observations that fit some criteria! In this case, lets just grab all the rows that have Adelie penguins and are above the mean body mass 


:::{.panel-tabset}

## R

```{r}

penguins |>
filter(species == "Adelie", body_mass_g > mean(body_mass_g, na.rm = TRUE))


```




## Python 



```{python}
#| error: true
penguins.filter(pl.col("species") == "Adelie" &
                pl.col("body_mass_g" > mean(pl.col("body_mass_g"))))



```

:::

This is my first attempt at it! It looks like the problem  I am running into is that Python does not have a `base python` where a function like mean is defined. 

After fiddling with it for some time it turns out the filter call is actually not correctly defined either! So before each filter option, you need to add a set of `()`

:::{.panel-tabset}

## R

```{r}

penguins |>
filter(species == "Adelie", body_mass_g > mean(body_mass_g, na.rm = TRUE))



```




## Python 



```{python}
#| error: true

penguins.filter((pl.col("species") == "Adelie") &
                (pl.col("body_mass_g") > pl.col("body_mass_g").mean()))



```

:::

Nobody said this was going to be pretty or seamless! One other thing to get used to is that we are not going to be using something crazy like `%in%` for set membership! We use `is_in` 


:::{.panel-tabset}

## R

```{r}

penguins |>
filter(species %in% c("Gentoo", "Chinstrap"),
       bill_depth_mm > median(bill_depth_mm, na.rm = TRUE))



```




## Python 



```{python}
#| error: true

penguins.filter((pl.col("species").is_in(["Chinstrap", "Gentoo"])) & 
                (pl.col("bill_depth_mm") > pl.col("bill_depth_mm").median()))


```

:::


One other thing that is weird (to me at least) is that you do not have to set the polars functions to remove NA's by default! Which I suppose is nice? But feels a bit wrong and weird to me as an R user. 



# Select 


In some cases, we have a dataset with extraneous columns we do not care for. Let's do a really extreme example 



:::{.panel-tabset}

## R 

```{r}

penguins |>
select(island)

```

## Python

```{python}

penguins.select((pl.col("island")))


```


:::


OKAY! first try now we are cooking! If we wanted to do multiple columns we would do something to the effect of


:::{.panel-tabset}

## R

```{r}

penguins |>
select(species, island)



```




## Python 

To do multiple columns we could do something to the effect of this:


```{python}
#| error: true

penguins.select((pl.col("species", "island")))


```

:::

Which feels more natural to me, but to some extent a dictionary would probably be more pythony.


One thing I use all the time is using tidyselectors like `starts_with` 


:::{.panel-tabset}

## R

```{r}

penguins |>
select(starts_with("bill"))



```




## Python 



```{python}
#| error: true

penguins.select(cs.starts_with("bill"))


```

:::

This is actually so cool that in this case it works exactly like the tidyverse selector functions! 



# Mutate 

Okay we have worked with subsets now we need to actually create some things. We should also work on chaining things together. Lets first with doing math stuff to the columns. Lets start with how I think it works in polars and if it errors then we can go and fix it



:::{.panel-tabset}

## R

```{r}

penguins |>
mutate(sqr_bill_length = bill_length_mm^2) |>
select(sqr_bill_length) |>
head()


```




## Python 



```{python}
#| error: true

penguins.mutate({pl.col("bill_length_mm")^2: "sqr_bill_length"}).select(pl.col("sqr_bill_length"))


```

:::


Okay where I am coming from is that in my head what we are doing is using the same logic as renaming columns. Lets fix it. So the first problem is that there is no `mutate` verb. Instead we use `with_column` 



```{python}



penguins.with_columns(sqr_bill_length = pl.col("bill_length_mm")**2).select(pl.col("sqr_bill_length")).head()

```


Okay this is the general idea. One of the big advantages of mutate is that we chain things together in the same mutate col. So lets say we wanted to square something than return it back to the original value


:::{.panel-tabset}


## R 

```{r}

penguins |>
mutate(sqr_bill = bill_length_mm^2,
       og_bill = sqrt(sqr_bill)) |>
       select(sqr_bill, og_bill, bill_length_mm) |>
       head(n = 5)



```



## Python 



```{python}



penguins.with_columns(sqr_bill = pl.col("bill_length_mm")**2).with_columns(og_bill = pl.col("sqr_bill").sqrt()).select(pl.col("sqr_bill", "og_bill", "bill_length_mm")).head(5)


```


:::


Now the next step is creating conditionals 



:::{.panel-tabset}


## R 

```{r}

penguins |>
mutate(female = ifelse(sex == "female", TRUE, FALSE)) |>
select(sex, female) |>
head(5)



```



## Python 



```{python}


penguins.with_columns(female = pl.when(pl.col("sex") == "female").then(True).otherwise(False)).select(["sex", "female"]).head(5)


```


:::

Full disclosure this took a much longer time than shown but this is the basic idea. Lets do this to keep myself a bit more honest. Recreate a silly example that I use to teach ifelse using the starwars dataset. 


```{r}
data("starwars")

write_csv(starwars, "starwars.csv")

```


:::{.panel-tabset}


## R 

```{r}

starwars |>
mutate(dog_years = birth_year * 7,
       comment = paste(name, "is", dog_years, "in dog years")) |>
       select(name, dog_years, comment) |>
       head(5)



```



## Python 



```{python}
#| error: true

starwars = pl.read_csv("starwars.csv")

starwars.with_columns(dog_years = pl.col("birth_year") * 7).with_columns(dog_years_string = pl.col("dog_years").cast(str)).with_columns(comment = pl.col("name") + " is " + pl.col("dog_years_string") + " in dog years ")

```


:::

It turns out that the column was actually a string 





```{python}
#| error: true

starwars.glimpse()

starwars.with_columns(dog_years = pl.col("birth_year").str.to_integer(strict = False)*7).with_columns(dog_years_string = pl.col("dog_years").cast(pl.String)).with_columns(comment = pl.col("name") + " is " + pl.col("dog_years_string")  + " in dog years").select(pl.col("name", "dog_years", "comment"))

```



Lets also do this for penguins but make it fun 




```{python}

penguins.with_columns(big_peng = pl.when(pl.col("body_mass_g") > pl.col("body_mass_g").mean()).then(True).otherwise(False))
```





## Group by and summarize


Last but not least we need to do the group by and summarise bit. It looks like this is slightly more intuitive


:::{.panel-tabset}


## R 

```{r}

penguins |>
group_by(species) |>
summarise(total = n())



```



## Python 



```{python}
#| error: true

penguins.group_by(pl.col("species")).agg(total = pl.count())

```


:::


Lets do some mathy stuff 


```{python}

penguins.group_by(pl.col("species")).agg(count = pl.len(),
                                         mean_flipp = pl.mean("flipper_length_mm"),
                                         median_flipp = pl.median("flipper_length_mm"))

```


A thing that is useful in summarize is that we can use our selectors to summarise across multiple columns like this 




```{r}

penguins |>
group_by(species) |>
summarise(across(starts_with("bill"), list(mean = \(x) mean(x, na.rm = TRUE,
                                           median = \(x) median(x, na.rm,  TRUE)))))



```



In polars I imagine it would probably be something like this 




```{python}
#| error: true

penguins.group_by(pl.col("species")).agg(cs.starts_with("bill").mean())


```


The think I am running into now is that I would like to add a `_` without doing any extra work. It looks like according to the docs it should be this 



```{python}

penguins.group_by(pl.col("species")).agg(cs.starts_with("bill").mean().name.suffix("_mean"),
                                         cs.starts_with("bill").median().name.suffix("_median"))

```


# Misc stuff that are usefull but not neccessarilly useful all the time 

Here are the collection of misfits that I thought would be useful 


### Slice(family)

One useful thing that I use all the time when testing out various things I am doing is using slice. This can be specific rows or a random sample of rows! 


If we wanted specific rows we could do this with `slice` 

:::{.panel-tabset}

## R

```{r}

penguins |>
slice(90:100)


```




## Python 



```{python}
#| error: true

penguins.slice(89:10)


```

:::


It looks like the R user in me strikes. So in polars if you wanted to do the same thing you give the starting number of the row you want and the length of the row you want. So we would rewrite the code like this 




:::{.panel-tabset}

## R

```{r}

penguins |>
slice(90:100)


```




## Python 



```{python}
#| error: true

penguins.slice(89,10)


```

:::

I actually quite like the syntax of the python version better. It is just annoying having to reset my thinking to start counting at `0`




### Slice Sample 

I find it useful to take a random sample of rows and test functions. It is nice for the function to work on a set of examples you come up with but not everything is consistent so lopping off chunks of a dataset and seeing if it still works is useful. 



:::{.panel-tabset}

## R

```{r}
set.seed(1994)
penguins |>
slice_sample(n = 10)

```




## Python 



```{python}
#| error: true

penguins.sample(n = 10, seed = 1994)


```

:::

Luckily the syntax is broadly the same! 



### Renaming 

I am a simple man I like snake_case but lets say I am more camel case inclined. I may want to rename columns that I am using as to not deal with object not found messages because I am used to typing billLengthMm. In the tidyverse we would do 


:::{.panel-tabset}

## R

```{r}

penguins |>
rename(BillLengthMm = bill_length_mm,
       BillDepthMm = bill_depth_mm)


```




## Python 



```{python}
#| error: true

penguins = penguins.rename({"bill_length_mm": "BillLengthMm",
                "bill_depth_mm" : "BillDepthMm"})


```

:::


In effect the thing you need to switch in your head when working in polars is that the order goes `old_name`:`new_name` I assigned it to an object because I wanted to test out a module I found online.



### Batch renaming 

Often times if we download data from the internet the column names are a mess and we want to rename them all at once. The janitor package in R is extra handy

Lets say we wanted to mass produce a camel case across the entire dataframe. In `R` that is a fairly simple task. Is it the case for python? 



:::{.panel-tabset}

## R

```{r}

penguins |>
janitor::clean_names(case = "lower_camel")


```




## Python 



```{python}
#| error: true
from janitor import clean_names

penguins.clean_names()


```

:::


In my head it looks like this. Where we are effectively chaining clean names to the dataframe. From the documentation it looks like this 



:::{.panel-tabset}

## R

```{r}

penguins |>
janitor::clean_names(case = "small_camel")


```




## Python 



```{python}
#| error: true

clean_names(penguins)


```

:::


Okay the trick it looks like is that it does not work with polars objects. So we need to pass it to pandas and then back to polars. 




```{python}
import pandas as pd 

penguins.glimpse()

penguins_pd = penguins.to_pandas()

penguins_clean = clean_names(penguins_pd, case_type = "snake")

penguins = pl.from_pandas(penguins_clean)

penguins.glimpse()


```


This works which is awesome! We got back to the original dataset naes 



## Make a column into a vector


In R there are like a ton of different ways to do this 



```{r}

vec1 = penguins$bill_depth_mm

vec2 = penguins |>
pluck("bill_depth_mm")

vec3 = penguins |>
select(bill_depth_mm) |>
deframe()



```

In polars the equivalent of this 

```{python}

vec1 = penguins["bill_depth_mm"]

print(vec1[0,1])


```


:::{.panel-tabset}

## R

```{r}

vec1[1:3]

```




## Python 



```{python}
#| error: true

import numpy as np 

print(vec1[0:2])


```

:::


