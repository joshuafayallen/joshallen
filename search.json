[
  {
    "objectID": "teaching/index.html",
    "href": "teaching/index.html",
    "title": "Teaching",
    "section": "",
    "text": "Introduction to American Government \n            \n            \n                Pols 1101 | \n                Georgia State University\n            \n            Introduction to American Government\n            \n                 Fall 2022\n                 Summer 2022\n                 Spring 2022\n            \n        \n    \n    \n        \n            \n        \n        \n            \n                Introduction to Political Science Research \n            \n            \n                Pols 3800 | \n                Georgia State University\n            \n            This course serves as an introduction research methods, casual inference, applied statistics, and using R. During the semester we will cover how to develop research questions, theory development, and how to answer questions about political phenomena\n            \n                 Spring 2023\n                 Summer 2023\n                 Fall 2023\n            \n        \n    \n    \n        \n            \n        \n        \n            \n                R Workshops \n            \n            \n                 | \n                Georgia State University\n            \n            Research Data Services R Workshops\n            \n                 Spring 2023\n                 Fall 2022\n            \n        \n    \n\n\nNo matching items"
  },
  {
    "objectID": "teaching/index.html#section",
    "href": "teaching/index.html#section",
    "title": "Teaching",
    "section": "",
    "text": "Introduction to American Government \n            \n            \n                Pols 1101 | \n                Georgia State University\n            \n            Introduction to American Government\n            \n                 Fall 2022\n                 Summer 2022\n                 Spring 2022\n            \n        \n    \n    \n        \n            \n        \n        \n            \n                Introduction to Political Science Research \n            \n            \n                Pols 3800 | \n                Georgia State University\n            \n            This course serves as an introduction research methods, casual inference, applied statistics, and using R. During the semester we will cover how to develop research questions, theory development, and how to answer questions about political phenomena\n            \n                 Spring 2023\n                 Summer 2023\n                 Fall 2023\n            \n        \n    \n    \n        \n            \n        \n        \n            \n                R Workshops \n            \n            \n                 | \n                Georgia State University\n            \n            Research Data Services R Workshops\n            \n                 Spring 2023\n                 Fall 2022\n            \n        \n    \n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Josh Allen",
    "section": "",
    "text": "Welcome to my website! My name is Josh Allen and I am a PhD Candidate in the Department of Political Science at Georgia State University. I earned my M.A. at Georgia State and am a proud Sonoma State University alum.\nMy research focuses on the impact of the Holocaust on contemporary political attitudes in Europe."
  },
  {
    "objectID": "blog/2022/2022-03-11-using-r-to-streamline-midsemester-reports/index.html",
    "href": "blog/2022/2022-03-11-using-r-to-streamline-midsemester-reports/index.html",
    "title": "Streamlining Midsemester Reports With The Tidyverse",
    "section": "",
    "text": "At GSU, we have Early Alert that is meant to connect students with resources if they are not doing well in the first few weeks of classes. While setting up your rules of thumb is up to you, this can quickly soak up an entire day if you are going row by row in your class of 60 or more students. To streamline the process I turned to R because it is a fairly simple data cleaning task.\nOur learning management software likes to add lots of extra stuff to the column names in our data. While most of us would come up with a more concise name like Chapter_4 our software names is Chapter 4.2 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt; we could use janitor::clean_names to eliminate some of the extraneous stuff iCollege will get grumpy at us. We could do this in Excel, and I have done it in the past, I figured I could speed this up in R while avoiding the headaches of ensuring each and every column is where it should be.\n\nlibrary(tidyverse)\n\nset.seed(1994)\n\nstudents = 26\n\n\ndat = tibble(id = 1:26,\n             Students = LETTERS,\n             `Chapter 4.2 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;` = rnorm(students, mean = 90, sd = 5),\n            `Chapter 4.3 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;` = rnorm(students, mean = 90, sd = 5),\n            `Chapter 4.4  Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;` = rnorm(students, mean = 90, sd = 5),\n            `Chapter 4.5  Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;` = rnorm(students, mean = 90, sd = 5),\n            `Exam 1 Points Grade &lt;Numeric MaxPoints:55 Weight 10 Category: Exams` = rnorm(students, mean = 85, sd = 3))  \n\nIn this simple example there are only 5 columns they have annoying names sure but it is not that bad. We can probably copy and paste them and we will be fine. However, in my real data there are 13 or so chapters with a few subsections in each of them. So this can get out from under us kind of quick and copy and pasting does not make our lives any easier. We also usually get columns that do not help us. Our ID variable is not doing anything other than providing the same info in a less transparent way than the student name variable, and more minor items like surveys which do not have a lot of weight on their final grade.\nI just used rnorm for convenience; however your data is more likely to have some missing values because students did not do stuff so it looks like this.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nStudents\nChapter 4.2 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;\nChapter 4.3 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;\nChapter 4.4 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;\nChapter 4.5 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;\nExam 1 Points Grade &lt;Numeric MaxPoints:55 Weight 10 Category: Exams\nsurveys\n\n\n\n\n1\nA\n83.56343\n81.70468\n85.71587\n85.97115\n83.71489\n100\n\n\n2\nB\n91.44406\n86.12473\n91.53892\n91.80590\n84.62108\n100\n\n\n3\nC\n98.50185\n89.76872\n91.79794\nNA\n85.11662\n100\n\n\n4\nD\n96.99304\n88.53903\n83.42538\n92.42625\n86.08429\n100\n\n\n5\nE\n90.49552\n92.64055\n93.27846\n89.24096\n80.39882\n100\n\n\n6\nF\n83.30126\n86.91250\n90.75522\n83.04509\n78.98100\n100\n\n\n7\nG\n94.03755\n81.34807\n87.57366\n99.04721\n80.11158\n100\n\n\n8\nH\n89.47185\n89.62792\n91.37094\n96.30433\n89.58399\n100\n\n\n9\nI\n92.78107\nNA\n96.44479\n87.20809\n81.31118\n100\n\n\n10\nJ\n83.04019\n88.74052\nNA\n96.58848\n85.93511\n100\n\n\n11\nK\n91.57146\nNA\n87.94661\n93.73501\n88.43763\n100\n\n\n12\nL\n94.18791\n89.64253\n90.53395\n88.29499\n86.82630\n100\n\n\n13\nM\n95.96341\n94.94366\n91.53490\n85.17583\n82.57437\n100\n\n\n14\nN\n84.91042\n90.50202\n93.41616\n87.64364\n83.46703\n100\n\n\n15\nO\n92.76743\n81.32158\n84.05944\n103.32883\n87.00560\n100\n\n\n16\nP\n92.48953\n93.73259\n91.46155\n93.64285\n87.11260\n100\n\n\n17\nQ\n91.88890\n91.99284\n95.01500\n95.61172\n84.63614\n100\n\n\n18\nR\n87.25405\n89.89440\n91.07664\n91.93496\n89.64706\n100\n\n\n19\nS\n83.62513\n82.48662\nNA\n92.74020\n90.45662\n100\n\n\n20\nT\n87.91310\n92.87887\n95.78937\n84.74539\n86.05332\n100\n\n\n21\nU\n91.36955\n96.67913\n90.59384\n87.86449\n79.76733\n100\n\n\n22\nV\n91.30800\n87.35611\n88.29575\n90.40188\n89.97015\n100\n\n\n23\nW\nNA\n89.35205\n97.02888\nNA\n82.47724\n100\n\n\n24\nX\n94.06035\n83.28452\n97.71377\n82.26974\n90.26051\n100\n\n\n25\nY\nNA\n91.24920\n96.15636\n88.80131\n90.26133\n100\n\n\n26\nZ\n94.57923\n93.57157\n91.66163\n91.83234\n84.33456\n100\n\n\n\n\n\nSo for the purpose of the report I treat NA’s as zeros. If you are dealing with multiple columns this is a pretty easy step just use mutate(across) and using some combination of starts_with, contains, everything, or ends_with to achieve the desired goal.\n\nimputed =  dat_miss %&gt;%\n  mutate(across(c(starts_with(\"exam\"), starts_with(\"chapter\"), \n                  ), ~replace(., is.na(.), 0)))\n\nSo that should take care of the NA's but we still need to generate our indicators. The assignments that carry the most weight are exams and the chapters, so I focus the most on those. In my use case, taking the sum makes sense, but for yours the average is probably the better option. Thankfully, while the learning management software names are a bit cumbersome, they do share something in common. So we can use mutate(across) and rowwise to make our life easier. rowwise is a pretty neat little function that works perfectly for this task where you are trying to do things for each student. Then you can use case_when or ifelse to generate a logical to create your flag. This is a toy example, but we can quickly start to build it out for our specific use cases. Using a mixture of apply and select you can achieve the same thing.\n\n flag = imputed %&gt;% \n  rowwise() %&gt;% \n  mutate(flag_dplyr = round(sum(across(starts_with(\"chapter\")))))\n\n\nflag$flag_apply = imputed %&gt;% \n  select(contains(\"chapter\")) %&gt;% \n  apply(., 1, function(row){\n    round(sum(row))\n  })\n\nCool, we can use this for our basic stuff, but I tend to weigh exams by how well students did. So your highest exam score counts for more, and your lowest exam has the least amount of weight. As with lots of things in R you can do this a few ways. There is probably a more concise way of doing this with apply it is ugly but works.\n\nexams_complete = imputed %&gt;% \n  mutate(`Exam 2 Points Grade &lt;Numeric MaxPoints:55 Weight 10 Category: Exams` = rnorm(students, mean = 70, sd = 11),\n         `Exam 3 Points Grade &lt;Numeric MaxPoints:55 Weight 10 Category: Exams` = rnorm(students, mean = 75, sd = 11))\n\n\n\nexams_complete$higest_exam_apply = exams_complete %&gt;%  \n  select(contains(\"Exam\")) %&gt;% \n  apply(., 1, function(row){\n    round(max(row))\n  })\n\n\nexams_complete = exams_complete %&gt;% \n  rowwise() %&gt;% \n  mutate(hig_exam_dplyr = round(max(c_across(contains(\"Exam\")))))\n\nexams_complete$lowest_exam_apply = exams_complete %&gt;%  \n  select(contains(\"Exam\")) %&gt;% \n  apply(., 1, function(row){\n    round(min(row))\n  })\n\nexams_complete = exams_complete %&gt;% \n  rowwise() %&gt;% \n  mutate(low_exam_dplyr = round(min(c_across(contains(\"Exam\")))))\n\nSo this is easy enough because we are just changing what we are doing with our summary function, but what about the second highest exam score? In this case you are going to have to use some trickery to get what you want\n\nexams_complete$second_highest = exams_complete %&gt;% \n  select(starts_with(\"Exam\")) %&gt;% \n  apply(., 1, function(row){\n    round(sort(row, decreasing = TRUE)[2])\n  })\n\nThis is simple enough and you can just use select and filter to get the info you want. However, as we all know we have to do some grading. You can use all your favorite dplyr tricks to grade and impute grades. This is the easy part, and now you can start to expand this out to using R to automate calculating grades. One super neat assignment all Intro to Government students at Georgia State do is assigning an adult field trip of sorts that is free for them. The students go to the National Center for Civil and Human Rights and do a tour and simulation of the lunch counter sit-ins. There are a few components to this: they submit a unique code as part of the proof that they have done it. Naturally, as is the case, some students just did not do it, but that nbd just use our friend left join, but to retain all the students be sure to include keep = TRUE so each student gets graded.\n\ncodes_data = tibble(id = 1:10,\n             Students = LETTERS[1:10],\n             code = 100)\n\n\nexams_complete = mutate(exams_complete, Code = NA)\n\n\ngrades_with_codes = left_join(exams_complete, codes_data, by = \"Students\", keep = TRUE) %&gt;% \n  mutate(Code = code,\n         Code = ifelse(is.na(Code), 0, Code)) %&gt;% \n  rename(id = id.x,\n         students = Students.x) %&gt;% \n  select(-id.y, -Students.y, -code)\n\nIn the real data, I join by using last names, which works for the most part. But you may need to check to make sure that your LMS has correctly spelled your students’ last name or, just as importantly, they spelled their last name correctly. Hopefully, this helps somebody. If not, at least it is tucked in a nice blog post. Be sure to check everything to make sure it is working, but if it works correctly then hopefully , you get a nice graded dataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nstudents\nChapter 4.2 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;\nChapter 4.3 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;\nChapter 4.4 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;\nChapter 4.5 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;\nExam 1 Points Grade &lt;Numeric MaxPoints:55 Weight 10 Category: Exams\nsurveys\nExam 2 Points Grade &lt;Numeric MaxPoints:55 Weight 10 Category: Exams\nExam 3 Points Grade &lt;Numeric MaxPoints:55 Weight 10 Category: Exams\nhigest_exam_apply\nhig_exam_dplyr\nlowest_exam_apply\nlow_exam_dplyr\nsecond_highest\nCode\n\n\n\n\n1\nA\n83.56343\n81.70468\n85.71587\n85.97115\n83.71489\n100\n58.06166\n68.83867\n84\n84\n58\n58\n69\n100\n\n\n2\nB\n91.44406\n86.12473\n91.53892\n91.80590\n84.62108\n100\n69.96645\n73.51084\n85\n85\n70\n70\n74\n100\n\n\n3\nC\n98.50185\n89.76872\n91.79794\n0.00000\n85.11662\n100\n66.30306\n74.42536\n85\n85\n66\n66\n74\n100\n\n\n4\nD\n96.99304\n88.53903\n83.42538\n92.42625\n86.08429\n100\n65.79288\n85.94456\n86\n86\n66\n66\n86\n100\n\n\n5\nE\n90.49552\n92.64055\n93.27846\n89.24096\n80.39882\n100\n88.72094\n64.87935\n89\n89\n65\n65\n80\n100\n\n\n6\nF\n83.30126\n86.91250\n90.75522\n83.04509\n78.98100\n100\n80.41976\n73.06732\n80\n80\n73\n73\n79\n100\n\n\n7\nG\n94.03755\n81.34807\n87.57366\n99.04721\n80.11158\n100\n86.56743\n66.79291\n87\n87\n67\n67\n80\n100\n\n\n8\nH\n89.47185\n89.62792\n91.37094\n96.30433\n89.58399\n100\n87.48637\n74.13581\n90\n90\n74\n74\n87\n100\n\n\n9\nI\n92.78107\n0.00000\n96.44479\n87.20809\n81.31118\n100\n69.63665\n68.36826\n81\n81\n68\n68\n70\n100\n\n\n10\nJ\n83.04019\n88.74052\n0.00000\n96.58848\n85.93511\n100\n69.71254\n71.65925\n86\n86\n70\n70\n72\n100\n\n\n11\nK\n91.57146\n0.00000\n87.94661\n93.73501\n88.43763\n100\n71.99278\n78.33438\n88\n88\n72\n72\n78\n0\n\n\n12\nL\n94.18791\n89.64253\n90.53395\n88.29499\n86.82630\n100\n66.30946\n99.16532\n99\n99\n66\n66\n87\n0\n\n\n13\nM\n95.96341\n94.94366\n91.53490\n85.17583\n82.57437\n100\n71.14509\n62.94670\n83\n83\n63\n63\n71\n0\n\n\n14\nN\n84.91042\n90.50202\n93.41616\n87.64364\n83.46703\n100\n66.72115\n67.17081\n83\n83\n67\n67\n67\n0\n\n\n15\nO\n92.76743\n81.32158\n84.05944\n103.32883\n87.00560\n100\n88.98898\n66.12589\n89\n89\n66\n66\n87\n0\n\n\n16\nP\n92.48953\n93.73259\n91.46155\n93.64285\n87.11260\n100\n63.42139\n77.70564\n87\n87\n63\n63\n78\n0\n\n\n17\nQ\n91.88890\n91.99284\n95.01500\n95.61172\n84.63614\n100\n70.82987\n53.49421\n85\n85\n53\n53\n71\n0\n\n\n18\nR\n87.25405\n89.89440\n91.07664\n91.93496\n89.64706\n100\n69.95649\n86.20525\n90\n90\n70\n70\n86\n0\n\n\n19\nS\n83.62513\n82.48662\n0.00000\n92.74020\n90.45662\n100\n78.62938\n64.34364\n90\n90\n64\n64\n79\n0\n\n\n20\nT\n87.91310\n92.87887\n95.78937\n84.74539\n86.05332\n100\n84.55215\n80.42847\n86\n86\n80\n80\n85\n0\n\n\n21\nU\n91.36955\n96.67913\n90.59384\n87.86449\n79.76733\n100\n75.08180\n64.40788\n80\n80\n64\n64\n75\n0\n\n\n22\nV\n91.30800\n87.35611\n88.29575\n90.40188\n89.97015\n100\n68.53960\n79.79600\n90\n90\n69\n69\n80\n0\n\n\n23\nW\n0.00000\n89.35205\n97.02888\n0.00000\n82.47724\n100\n88.95738\n70.28810\n89\n89\n70\n70\n82\n0\n\n\n24\nX\n94.06035\n83.28452\n97.71377\n82.26974\n90.26051\n100\n63.12942\n78.58372\n90\n90\n63\n63\n79\n0\n\n\n25\nY\n0.00000\n91.24920\n96.15636\n88.80131\n90.26133\n100\n88.82365\n86.03999\n90\n90\n86\n86\n89\n0\n\n\n26\nZ\n94.57923\n93.57157\n91.66163\n91.83234\n84.33456\n100\n65.54887\n82.58063\n84\n84\n66\n66\n83\n0"
  },
  {
    "objectID": "CV/index.html",
    "href": "CV/index.html",
    "title": "Curriculum vitae",
    "section": "",
    "text": "Download current CV"
  },
  {
    "objectID": "blog/2022/2021-11-25-what-to-do-when-you-break-r/index.html",
    "href": "blog/2022/2021-11-25-what-to-do-when-you-break-r/index.html",
    "title": "What to do when you break R",
    "section": "",
    "text": "Hi all, when I first stated using R I tried making my website using blogdown. While Alison Hill PhD provides an excellent intro to launching your website. However, I am truly special and managed to mess this process up. For a few days whenever I did anything more computationally intensive than\n\nrm(list=ls())\nlibrary(tidyverse)\n\nI would get a nasty error message saying “c stack usage is too close to the limit” and I could not do anything. This would have been fine but at the time I was still taking classes and need to have R working to complete the problem sets.\nSo what did I do to get in the c stack death spiral and how did it end up being fixed? For the former you should not skip steps in Dr. Hill’s post. For the later well to spare you the long arduous process here is what we tried.\n\nme consulting stackoverflow & realizing I really f****k up\nrestarting my computer\nuninstalling & reinstalling blogdown\nuninstalling & reinstalling R\nuninstalling & reinstalling pandocs\n\nAfter hours of trouble shooting #rstats twitter came to the rescue when this distress signal was sent out.\n\n\n#rstats world! I have a student who is getting a \"c stack usage is too close to the limit\" every time when using knitr (even with an R-chunk-free Rmd file) & getting same error when trying to install anything with devtools or remotes. We've un/reinstalled R but no luck. Ideas?\n\n— Andrew Heiss (🐘 @andrew@fediscience.org) (@andrewheiss) February 7, 2021\n\n\nSo here is what ended up working. To start you will need a super simple Rmd file to test with in a local directory. I suggest starting a new Rmd file with nothing in it other than the default YAML header and “test” in the main body or “Lorem Ipsum” if you feel fancy.\nIn the terminal run the following code\n\ncd ~ \n\nls -la\n\nThen look for files starting with a period. Okay if you messed up in the initial blogdown setup you are looking for the “.Rprofile” that is causing you the problem. What ended up happening is that you broke all of R by including a recursive function. So restarting and uninstalling R will not kill the function it will be there\n\n\n\nWhat you are going to do is open a terminal in Rstudio or otherwise than start running this.\n\ncat.Rprofile\n\nthan run\n\ncat.zshrc\n\nthan after that run\nmv. Rprofile .Rprofile-original\nThen close out Rstudio and reopen Rstudio. Then try to knit your super simple Rmd file and install a package and doing something fun! Than knit that file.\nHopefully the dreaded C stack usage error is gone. If it is than celebrate\n\n\n\nbecause you can use R again!!!!"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "March 11, 2022\n        \n        \n            Streamlining Midsemester Reports With The Tidyverse\n            \n                \n                    r\n                \n                \n                    tidyverse\n                \n            \n            Working with LMS data using the tidyverse\n        \n    \n    \n                  \n            January 1, 2022\n        \n        \n            What to do when you break R\n            \n                \n                    r\n                \n                \n                    zsh\n                \n            \n            What happens when you keep getting c stack usage errors \n        \n    \n\n\nNo matching items"
  },
  {
    "objectID": "blog/index.html#section",
    "href": "blog/index.html#section",
    "title": "Blog",
    "section": "",
    "text": "March 11, 2022\n        \n        \n            Streamlining Midsemester Reports With The Tidyverse\n            \n                \n                    r\n                \n                \n                    tidyverse\n                \n            \n            Working with LMS data using the tidyverse\n        \n    \n    \n                  \n            January 1, 2022\n        \n        \n            What to do when you break R\n            \n                \n                    r\n                \n                \n                    zsh\n                \n            \n            What happens when you keep getting c stack usage errors \n        \n    \n\n\nNo matching items"
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Research and Projects",
    "section": "",
    "text": "Allen Joshua. “The Use of The Holocaust in Online Discourse and in Media: A Computational Approach”\nAllen Joshua. “Collective Memory and Contemporary Political Behavior: Evidence from France”"
  },
  {
    "objectID": "research/index.html#working-papers",
    "href": "research/index.html#working-papers",
    "title": "Research and Projects",
    "section": "",
    "text": "Allen Joshua. “The Use of The Holocaust in Online Discourse and in Media: A Computational Approach”\nAllen Joshua. “Collective Memory and Contemporary Political Behavior: Evidence from France”"
  },
  {
    "objectID": "research/index.html#dormant-papers",
    "href": "research/index.html#dormant-papers",
    "title": "Research and Projects",
    "section": "Dormant Papers",
    "text": "Dormant Papers\n\nAllen Joshua. Testing The Effects of U.S. Airstrikes on Insurgent Initiated Violence in Yemen"
  }
]